{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "115f65d3",
   "metadata": {},
   "source": [
    "# Hands-On Pertemuan 9: Spark SQL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1597a968",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[1;32m      3\u001b[0m spark \u001b[38;5;241m=\u001b[39m SparkSession\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mappName(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtugas_9\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mgetOrCreate()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('tugas_9').getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0fa7f9",
   "metadata": {},
   "source": [
    "## Tujuan:\n",
    "- Mengasah keterampilan analisis data menggunakan Spark SQL.\n",
    "- Melakukan lebih banyak latihan SQL yang mengarah ke skenario dunia nyata.\n",
    "- Mempersiapkan mahasiswa untuk menggunakan Spark SQL dalam proyek besar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a45dcb9",
   "metadata": {},
   "source": [
    "### 1. Refresher: Basic SQL Operations in Spark SQL\n",
    "- **Tugas 1**: Ulangi pemahaman Anda tentang SQL dasar dengan menjalankan queries sederhana pada dataset di Spark SQL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "974a023b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+------+------+------+\n",
      "| Name|Age|Gender|Salary|DeptId|\n",
      "+-----+---+------+------+------+\n",
      "|James| 34|     M|  3000|     1|\n",
      "| Anna| 28|     F|  4100|     2|\n",
      "|  Lee| 23|     M|  2700|     1|\n",
      "+-----+---+------+------+------+\n",
      "\n",
      "+----+---+\n",
      "|Name|Age|\n",
      "+----+---+\n",
      "|Anna| 28|\n",
      "+----+---+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|       avg(Salary)|\n",
      "+------------------+\n",
      "|3266.6666666666665|\n",
      "+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    ('James', 34, 'M', 3000, 1),\n",
    "    ('Anna', 28, 'F', 4100, 2),\n",
    "    ('Lee', 23, 'M', 2700, 1)\n",
    "]\n",
    "columns = ['Name', 'Age', 'Gender', 'Salary', 'DeptId']\n",
    "df = spark.createDataFrame(data, schema=columns)\n",
    "df.createOrReplaceTempView('employees')\n",
    "spark.sql('SELECT * FROM employees').show()\n",
    "spark.sql('SELECT Name, Age FROM employees WHERE Salary > 3000').show()\n",
    "spark.sql('SELECT AVG(Salary) FROM employees').show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd8b4f1",
   "metadata": {},
   "source": [
    "### 2. Advanced Queries for Data Analysis\n",
    "Gunakan queries lebih kompleks, melibatkan grouping, filtering, dan subqueries.\n",
    "- **Tugas 2**: Buat SQL query yang menghitung total gaji berdasarkan jenis kelamin dan usia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc8a9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('''\n",
    "SELECT Gender, SUM(Salary) as TotalSalary, Age\n",
    "FROM employees\n",
    "GROUP BY Gender, Age\n",
    "ORDER BY Age\n",
    "''').show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b3ccb1",
   "metadata": {},
   "source": [
    "- **Tugas Tambahan 2**: \n",
    "1. Cari rata-rata gaji per departemen.\n",
    "2. Temukan karyawan yang memiliki gaji di atas rata-rata untuk gender masing-masing.\n",
    "3. Buat ranking karyawan berdasarkan gaji dalam departemen mereka.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4fffdc",
   "metadata": {},
   "source": [
    "### 3. Penggunaan Window Functions dan Subqueries\n",
    "Latihan penggunaan window functions untuk menemukan karyawan dengan gaji tertinggi dan urutannya berdasarkan kelompok usia.\n",
    "- **Tugas 3**: Terapkan window functions untuk menemukan top 3 karyawan dalam kelompok usia tertentu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb927310",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('''\n",
    "SELECT Name, Age, Salary, ROW_NUMBER() OVER (PARTITION BY Age ORDER BY Salary DESC) as rank\n",
    "FROM employees\n",
    "''').show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb43ac4",
   "metadata": {},
   "source": [
    "### 4. Advanced Spark SQL Queries\n",
    "Menjelajahi queries yang lebih kompleks yang melibatkan multiple joins, subqueries, dan window functions.\n",
    "- **Tugas 4**: Demonstrasi penggunaan multi-level joins dan subqueries untuk analisis data yang mendalam.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bfd9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Pertemuan9').getOrCreate()\n",
    "\n",
    "# Data setup for complex SQL queries\n",
    "employees = spark.createDataFrame([\n",
    "    ('James', 34, 'M', 3000, 1),\n",
    "    ('Anna', 28, 'F', 4100, 2),\n",
    "    ('Lee', 23, 'M', 2700, 1)\n",
    "], ['Name', 'Age', 'Gender', 'Salary', 'DeptId'])\n",
    "departments = spark.createDataFrame([\n",
    "    (1, 'HR'),\n",
    "    (2, 'Marketing')\n",
    "], ['DeptId', 'DeptName'])\n",
    "projects = spark.createDataFrame([\n",
    "    (1, 'Project A'),\n",
    "    (2, 'Project B')\n",
    "], ['DeptId', 'ProjectName'])\n",
    "employees.createOrReplaceTempView('employees')\n",
    "departments.createOrReplaceTempView('departments')\n",
    "projects.createOrReplaceTempView('projects')\n",
    "\n",
    "# Complex SQL query involving multiple joins and subqueries\n",
    "spark.sql('''\n",
    "SELECT e.Name, e.Age, d.DeptName, p.ProjectName\n",
    "FROM employees e\n",
    "JOIN departments d ON e.DeptId = d.DeptId\n",
    "JOIN projects p ON e.DeptId = p.DeptId\n",
    "''').show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad25f1f0",
   "metadata": {},
   "source": [
    "Latihan mandiri untuk memperkuat pemahaman tentang Spark SQL dalam analisis data terdistribusi.\n",
    "- **Tugas 5**: Tuliskan query SQL untuk menemukan rata-rata gaji per departemen dan rangking setiap karyawan dalam departemen berdasarkan gaji.\n",
    "- **Tugas 6**: Gunakan window functions untuk menentukan tren gaji berdasarkan usia di setiap departemen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a2c206",
   "metadata": {},
   "source": [
    "### 5. Advanced Data Analysis and Visualization\n",
    "Penerapan teknik analisis data yang lebih canggih dan visualisasi menggunakan PySpark dan matplotlib.\n",
    "- **Tugas 7**: Lakukan analisis tren gaji menggunakan Spark SQL dan visualisasikan hasilnya.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a170f256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Advanced data analysis with visualization\n",
    "salary_trends = spark.sql('''\n",
    "SELECT Age, AVG(Salary) AS AverageSalary\n",
    "FROM employees\n",
    "GROUP BY Age\n",
    "ORDER BY Age\n",
    "''').toPandas()\n",
    "\n",
    "# Visualization of salary trends\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(salary_trends['Age'], salary_trends['AverageSalary'], marker='o')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Average Salary')\n",
    "plt.title('Salary Trends by Age')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd314ae9",
   "metadata": {},
   "source": [
    "### 6. Homework\n",
    "- **Tugas 1**: Gunakan Spark SQL untuk mencari total gaji dan jumlah karyawan per departemen. Buat visualisasi perbandingan antar departemen.\n",
    "- **Tugas 2**: Temukan karyawan dengan gaji di atas rata-rata dalam setiap kelompok usia dan visualisasikan data ini dalam bentuk grafik batang atau pie chart.\n",
    "- **Tugas 3**: Buat dataset yang lebih besar (misalnya, 100+ baris) dan lakukan analisis mendalam menggunakan SQL functions seperti `SUM()`, `AVG()`, `COUNT()`, serta `JOIN` antar tabel.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
